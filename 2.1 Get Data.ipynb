{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import cv2                         # To read and manipulate images\n",
    "import matplotlib.pyplot as plt    # Python 2D plotting library\n",
    "%matplotlib inline  \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/CAX_Superhero_Train/'\n",
    "TEST_PATH = 'data/CAX_Superhero_Test/'\n",
    "superhero_dic = {'Ant-Man':'ant_man', 'Aquaman':'aqua_man', 'Avengers':'avengers', 'Batman':'bat_man', \n",
    "                 'Black Panther':'black_panther', 'Captain America':'captain_america', 'Catwoman':'cat_woman',\n",
    "                 'Ghost Rider':'ghostrider', 'Hulk':'hulk', 'Iron Man':'iron_man', 'Spiderman':'spider_man', \n",
    "                 'Superman':'super_man'}\n",
    "\n",
    "labelencoder_dic = {0: 'ant_man', 1: 'aqua_man', 2: 'avengers', 3: 'bat_man', 4: 'black_panther', 5: 'captain_america', \n",
    "                    6: 'cat_woman', 7: 'ghostrider', 8: 'hulk', 9: 'iron_man', 10: 'spider_man', 11: 'super_man'}\n",
    "\n",
    "#IMG_HEIGHT = 260\n",
    "#IMG_WIDTH = 200\n",
    "#IMG_HEIGHT = 224\n",
    "#IMG_WIDTH = 224\n",
    "IMG_HEIGHT = 32\n",
    "IMG_WIDTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_image(filepath, color_mode=cv2.IMREAD_COLOR, target_size=None):\n",
    "    \"\"\"Read an image from a file and resize it\"\"\"\n",
    "    img = cv2.imread(filepath, color_mode)\n",
    "    if target_size: \n",
    "        img = cv2.resize(img, target_size, interpolation = cv2.INTER_AREA)\n",
    "    return img\n",
    "\n",
    "def read_train_data_properties(train_dir):\n",
    "    \"\"\"Read basic properties of training images\"\"\"\n",
    "    tmp = []\n",
    "    for i,dir_name in enumerate(next(os.walk(train_dir))[1]):\n",
    "        img_dir = os.path.join(train_dir, dir_name)\n",
    "        superhero_dir = next(os.walk(img_dir))[2]\n",
    "        for j in range(len(superhero_dir)):\n",
    "            img_name = superhero_dir[j]\n",
    "            img_path = os.path.join(img_dir, img_name)\n",
    "            img_shape = read_image(img_path).shape\n",
    "            superhero = superhero_dic[dir_name]\n",
    "            tmp.append([img_name, img_shape[0], img_shape[1], img_shape[0]/img_shape[1], img_shape[2], superhero, img_path])\n",
    "\n",
    "    train_df = pd.DataFrame(tmp, columns = ['img_name','img_height', 'img_width',  'img_ratio', 'num_channels',\n",
    "                                            'superhero', 'img_path'])\n",
    "    return train_df\n",
    "\n",
    "def read_test_data_properties(test_dir):\n",
    "    \"\"\"Read basic properties of test images\"\"\"\n",
    "    tmp = []\n",
    "    img_dir = next(os.walk(test_dir))[2]\n",
    "    for i,img_name in enumerate(img_dir):\n",
    "        img_path = os.path.join(test_dir, img_name)\n",
    "        img_shape = read_image(img_path).shape\n",
    "        tmp.append([img_name, img_shape[0], img_shape[1], img_shape[0]/img_shape[1], img_shape[2], img_path])\n",
    "\n",
    "    test_df = pd.DataFrame(tmp, columns = ['img_name','img_height', 'img_width',  'img_ratio', 'num_channels', 'img_path'])\n",
    "    return test_df\n",
    "\n",
    "def load_raw_data(image_size=(IMG_HEIGHT, IMG_WIDTH)):\n",
    "    \"\"\"Load raw data.\"\"\"\n",
    "    # Python lists to store the training images/masks and test images.\n",
    "    labelencoder = LabelEncoder()\n",
    "    image_size=(IMG_HEIGHT, IMG_WIDTH)\n",
    "    x_train, y_train, x_test = [],[],[]\n",
    "\n",
    "    # Read and resize train images/superheroes. \n",
    "    print('Loading and resizing train images and labels ...')\n",
    "    os.sys.stdout.flush()\n",
    "    for i, filename in tqdm(enumerate(train_df['img_path']), total=len(train_df)):\n",
    "        img = read_image(train_df['img_path'].loc[i], target_size=image_size)\n",
    "        superhero = train_df['superhero'].loc[i] \n",
    "        x_train.append(img) \n",
    "        y_train.append(superhero)\n",
    "        \n",
    "    # Read and resize test images. \n",
    "    print('Loading and resizing test images ...')\n",
    "    os.sys.stdout.flush()\n",
    "    for i, filename in tqdm(enumerate(test_df['img_path']), total=len(test_df)):\n",
    "        img = read_image(test_df['img_path'].loc[i], target_size=image_size)\n",
    "        x_test.append(img)    \n",
    "        \n",
    "    # Transform lists into 4-dim numpy arrays (N,H,W,C)\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    \n",
    "    '''\n",
    "    # save to file labelencoder_dic\n",
    "    labelencoder_dic = dict(enumerate(labelencoder.classes_))\n",
    "    with open('labelencoder_dic.pkl', 'wb') as file:\n",
    "        pickle.dump(labelencoder_dic, file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    '''    \n",
    "      \n",
    "    return x_train, y_train, x_test\n",
    "\n",
    "# Shuffle two numpy arrays in the same order\n",
    "def randomize(a, b):\n",
    "    # Generate the permutation index array.\n",
    "    s = np.arange(a.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    # Shuffle the arrays by giving the permutation in the square brackets.\n",
    "    shuffled_a = a[s]\n",
    "    shuffled_b = b[s]\n",
    "    return shuffled_a, shuffled_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df:\n",
      "        img_height    img_width    img_ratio  num_channels\n",
      "count  5433.000000  5433.000000  5433.000000        5433.0\n",
      "mean    230.794773   197.981594     1.169293           3.0\n",
      "std      37.450213    24.658881     0.162639           0.0\n",
      "min     120.000000    73.000000     0.463636           3.0\n",
      "25%     200.000000   190.000000     1.000000           3.0\n",
      "50%     246.000000   200.000000     1.294737           3.0\n",
      "75%     260.000000   200.000000     1.300000           3.0\n",
      "max     522.000000   540.000000     3.561644           3.0\n",
      "test_df:\n",
      "        img_height    img_width    img_ratio  num_channels\n",
      "count  3375.000000  3375.000000  3375.000000        3375.0\n",
      "mean    233.944889   203.209185     1.159080           3.0\n",
      "std      36.831582    31.001904     0.160660           0.0\n",
      "min      80.000000    80.000000     0.561873           3.0\n",
      "25%     200.000000   190.000000     1.000000           3.0\n",
      "50%     246.000000   200.000000     1.294737           3.0\n",
      "75%     260.000000   200.000000     1.300000           3.0\n",
      "max     480.000000   400.000000     2.363636           3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Basic properties of images/masks\n",
    "train_df = read_train_data_properties(TRAIN_PATH)\n",
    "print('train_df:')\n",
    "print(train_df.describe())\n",
    "test_df = read_test_data_properties(TEST_PATH)\n",
    "print('test_df:')\n",
    "print(test_df.describe())\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('data/train_df.csv', index=False)\n",
    "test_df.to_csv('data/test_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 200)    1614\n",
       "(246, 190)    1262\n",
       "(180, 180)    1113\n",
       "(200, 200)     600\n",
       "(253, 253)     146\n",
       "(225, 225)     140\n",
       "(218, 218)      42\n",
       "(400, 400)      21\n",
       "(259, 194)      19\n",
       "(480, 360)      18\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting unique train image shapes.\n",
    "df = pd.DataFrame([[x] for x in zip(train_df['img_height'], train_df['img_width'])])\n",
    "df[0].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 200)    958\n",
       "(246, 190)    729\n",
       "(180, 180)    656\n",
       "(253, 253)    263\n",
       "(200, 200)    202\n",
       "(225, 225)    123\n",
       "(400, 400)     36\n",
       "(218, 218)     27\n",
       "(224, 224)     18\n",
       "(260, 230)     17\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting unique test image shapes.\n",
    "df = pd.DataFrame([[x] for x in zip(test_df['img_height'], test_df['img_width'])])\n",
    "df[0].value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and resizing train images and labels ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5433/5433 [00:09<00:00, 558.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and resizing test images ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 3375/3375 [00:06<00:00, 556.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Read images/labels from files and resize them. Each image is stored as a 3-dim array where the number of channels is 3\n",
    "train_df = read_train_data_properties(TRAIN_PATH)\n",
    "test_df = read_test_data_properties(TEST_PATH)\n",
    "x_train, y_train, x_test = load_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.2, random_state=42, \n",
    "                                                      shuffle=True, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4346, 32, 32, 3), (1087, 32, 32, 3))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save dataset to files\n",
    "np.save('data/x_train', x_train)\n",
    "np.save('data/y_train', y_train)\n",
    "np.save('data/x_valid', x_valid)\n",
    "np.save('data/y_valid', y_valid)\n",
    "np.save('data/x_test', x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alexnet = models.alexnet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alexnet = models.alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to C:\\Users\\Андрей/.torch\\models\\alexnet-owt-4df8aa71.pth\n",
      "100%|███████████████████████████████████████████████████████████████| 244418560/244418560 [00:41<00:00, 5960080.64it/s]\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.alexnet(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace)\n",
      "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Dropout(p=0.5)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(alexnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace)\n",
       "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.5)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alexnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv = torchvision.models.squeezenet1_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features\n",
      "classifier\n"
     ]
    }
   ],
   "source": [
    "for name, params in model_conv.named_children():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many In_channels are there for the conv layer\n",
    "in_ftrs = model_conv.classifier[1].in_channels\n",
    "in_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## How many Out_channels are there for the conv layer\n",
    "out_ftrs = model_conv.classifier[1].out_channels\n",
    "out_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dropout(p=0.5),\n",
       " Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1)),\n",
       " ReLU(inplace),\n",
       " AvgPool2d(kernel_size=13, stride=1, padding=0, ceil_mode=False, count_include_pad=True)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Converting a sequential layer to list of layers \n",
    "features = list(model_conv.classifier.children())\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Changing the conv layer to required dimension\n",
    "features[1] = nn.Conv2d(in_ftrs, n_class, kernel_size,stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SqueezeNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
      "    (3): Fire(\n",
      "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (4): Fire(\n",
      "      (squeeze): Conv2d(128, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(16, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
      "    (6): Fire(\n",
      "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (7): Fire(\n",
      "      (squeeze): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (8): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), dilation=(1, 1), ceil_mode=True)\n",
      "    (9): Fire(\n",
      "      (squeeze): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (10): Fire(\n",
      "      (squeeze): Conv2d(384, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (11): Fire(\n",
      "      (squeeze): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "    (12): Fire(\n",
      "      (squeeze): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (squeeze_activation): ReLU(inplace)\n",
      "      (expand1x1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (expand1x1_activation): ReLU(inplace)\n",
      "      (expand3x3): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (expand3x3_activation): ReLU(inplace)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5)\n",
      "    (1): Conv2d(512, 1000, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (2): ReLU(inplace)\n",
      "    (3): AvgPool2d(kernel_size=13, stride=1, padding=0, ceil_mode=False, count_include_pad=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_ftrs = model_conv.classifier[6].in_features\n",
    "num_ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_class = 12\n",
    "model_conv = models.alexnet(pretrained=True)\n",
    "# Number of filters in the bottleneck layer\n",
    "num_ftrs = model_conv.classifier[6].in_features\n",
    "# convert all the layers to list and remove the last one\n",
    "features = list(model_conv.classifier.children())[:-1]\n",
    "## Add the last layer based on the num of classes in our dataset\n",
    "features.extend([nn.Linear(num_ftrs, n_class)])\n",
    "## convert it into container and add it to our model class.\n",
    "model_conv.classifier = nn.Sequential(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_conv.train?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_base = nn.Sequential(\n",
    "                nn.Conv2d(3, 32, kernel_size=7, stride=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                Flatten(), # see above for explanation\n",
    "                nn.Linear(5408, 1024),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(1024, 10), # affine layer\n",
    "              )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
